{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The **gradient** is a vector that tells us in what direction the weights need to go. More precisely, it tells us how to change the weights to make the loss change fastest. \n",
    "- We call our process **gradient descent** because it uses the gradient to descend the loss curve towards a minimum. \n",
    "- **Stochastic** means \"determined by chance.\" Our training is stochastic because the minibatches are random samples from the dataset. And that's why it's called SGD! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Sample code\n",
    "'''\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(feature_array, target_array, to_predict, learn_rate_type=\"invscaling\"):\n",
    "    \"\"\" Computes Ordinary Least SquaresLinear Regression with Stochastic Gradient Descent as the optimization algorithm.\n",
    "        :param feature_array: array with all feature vectors used to train the model\n",
    "        :param target_array: array with all target vectors used to train the model\n",
    "        :param to_predict: feature vector that is not contained in the training set. Used to make a new prediction\n",
    "        :param learn_rate_type: algorithm used to set the learning rate at each iteration.\n",
    "        :return: Predicted cooking time for the vector to_predict and the R-squared of the model.\n",
    "\"\"\"    # Pipeline of transformations to apply to an estimator. First applies Standard Scaling to the feature array.\n",
    "    # Then, when the model is fitting the data it runs Stochastic Gradient Descent as the optimization algorithm.\n",
    "    # The estimator is always the last element.\n",
    "    \n",
    "    start_time = time.time()\n",
    "    linear_regression_pipeline = make_pipeline(StandardScaler(), SGDRegressor(learning_rate=learn_rate_type))\n",
    "    \n",
    "    linear_regression_pipeline.fit(feature_array, target_array)\n",
    "    stop_time = time.time()\n",
    "     \n",
    "    print(\"Total runtime: %.6fs\" % (stop_time - start_time))\n",
    "    print(\"Algorithm used to set the learning rate: \" + learn_rate_type)\n",
    "    print(\"Model Coeffiecients: \" + str(linear_regression_pipeline[1].coef_))\n",
    "    print(\"Number of iterations: \" + str(linear_regression_pipeline[1].n_iter_))    # Make a prediction for a feature vector not in the training set\n",
    "    prediction = np.round(linear_regression_pipeline.predict(to_predict), 0)[0]\n",
    "    print(\"Predicted cooking time: \" + str(prediction) + \" minutes\")    \n",
    "    r_squared = np.round(linear_regression_pipeline.score(feature_array, target_array).reshape(-1, 1)[0][0], 2)\n",
    "    print(\"R-squared: \" + str(r_squared))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_array = [[500, 80, 30, 10],\n",
    "                 [550, 75, 25, 0],\n",
    "                 [475, 90, 35, 20],\n",
    "                 [450, 80, 20,25],\n",
    "                 [465, 75, 30, 0],\n",
    "                 [525, 65, 40, 15],\n",
    "                 [400, 85, 33, 0],\n",
    "                 [500, 60, 30, 30],\n",
    "                 [435, 45, 25, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_array = [17, 11, 21, 23, 22, 15, 25, 18, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = [[510, 50, 35, 10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 0.005951s\n",
      "Algorithm used to set the learning rate: invscaling\n",
      "Model Coeffiecients: [-3.43412357  1.65035997  0.28225406  1.10689218]\n",
      "Number of iterations: 249\n",
      "Predicted cooking time: 13.0 minutes\n",
      "R-squared: 0.9\n"
     ]
    }
   ],
   "source": [
    "stochastic_gradient_descent(feature_array, target_array, to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 0.004002s\n",
      "Algorithm used to set the learning rate: invscaling\n",
      "Model Coeffiecients: [-3.43748524  1.64858234  0.2837066   1.10873186]\n",
      "Number of iterations: 248\n",
      "Predicted cooking time: 13.0 minutes\n",
      "R-squared: 0.9\n"
     ]
    }
   ],
   "source": [
    "stochastic_gradient_descent(feature_array, target_array, to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 0.002002s\n",
      "Algorithm used to set the learning rate: adaptive\n",
      "Model Coeffiecients: [-3.49474564  1.64238774  0.30445277  1.15701067]\n",
      "Number of iterations: 95\n",
      "Predicted cooking time: 13.0 minutes\n",
      "R-squared: 0.91\n"
     ]
    }
   ],
   "source": [
    "stochastic_gradient_descent(feature_array, target_array, to_predict, learn_rate_type=\"adaptive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "With the limitations of Gradient Descent in mind, Stochastic Gradient Descent emerged as a way to tackle performance issues and speed up the convergence in large datasets.\n",
    "\n",
    "Stochastic Gradient Descent is a probabilistic approximation of Gradient Descent. It is an approximation because, at each step, the algorithm calculates the gradient for one observation picked at random, instead of calculating the gradient for the entire dataset.\n",
    "'''\n",
    "src: https://towardsdatascience.com/stochastic-gradient-descent-explained-in-real-life-predicting-your-pizzas-cooking-time-b7639d5e6a32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_loop(runs=3):\n",
    "    \"\"\" Repeatedly computes the gradient of a function\n",
    "        Computes the gradient given the starting points and then uses the result of the gradient to feed the next iteration, with new points.\n",
    "        Prints out the result of the function at each iteration\n",
    "        :param: runs: number of iterations to compute\n",
    "    \"\"\"    # starting points\n",
    "    x = np.array([1, 2, 3])\n",
    "    \n",
    "    # quadratic function, a parabola\n",
    "    y = x**2\n",
    "    \n",
    "    for run in range(0, runs):\n",
    "        print(\"Iter \" + str(run) + \": Y=\" + str(y))        # compute first derivative\n",
    "        x = np.gradient(y, 1)        # update the function output\n",
    "        y = x ** 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0: Y=[1 4 9]\n",
      "Iter 1: Y=[ 9. 16. 25.]\n",
      "Iter 2: Y=[49. 64. 81.]\n",
      "Iter 3: Y=[225. 256. 289.]\n",
      "Iter 4: Y=[ 961. 1024. 1089.]\n",
      "Iter 5: Y=[3969. 4096. 4225.]\n",
      "Iter 6: Y=[16129. 16384. 16641.]\n",
      "Iter 7: Y=[65025. 65536. 66049.]\n",
      "Iter 8: Y=[261121. 262144. 263169.]\n",
      "Iter 9: Y=[1046529. 1048576. 1050625.]\n"
     ]
    }
   ],
   "source": [
    "gradient_loop(runs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Neural Network-Based SGD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the training data we have, we need two more things:\n",
    "- A **loss function** that measures how good the network's predictions are. it measures the disparity between the the target's true value and the value the model predicts.\n",
    "  -- A common loss function for regression problems is the **mean absolute error or MAE**. For each prediction y_pred, MAE measures the disparity from the true target y_true by an absolute difference abs(y_true - y_pred).\n",
    "- An **optimizer** that can tell the network how to change its weights. The optimizer is an algorithm that adjusts the weights to minimize the loss. \n",
    "  -- Virtually all of the optimization algorithms used in deep learning belong to a family called **stochastic gradient descent.**  They are iterative algorithms that train a network in steps. One step of training goes like this:\n",
    "\n",
    "    * Sample some training data and run it through the network to make predictions.\n",
    "    * Measure the loss between the predictions and the true values.\n",
    "    * Finally, adjust the weights in a direction that makes the loss smaller.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/batch-sgd.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='img/batch-sgd.gif')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each iteration's sample of training data is called a minibatch (or often just \"batch\"), while a complete round of the training data is called an epoch. The number of epochs you train for is how many times the network will see each training example.\n",
    "- The pale red dots depict the entire training set, while the solid red dots are the minibatches. \n",
    "- Every time SGD sees a new minibatch, it will shift the weights (w the slope and b the y-intercept) toward their correct values on that batch. Batch after batch, the line eventually converges to its best fit. \n",
    "- We can see that the loss gets smaller as the weights get closer to their true values.\n",
    "\n",
    "\n",
    "It is also important to note that:\n",
    "- the line only makes a small shift in the direction of each batch (instead of moving all the way). The size of these shifts is determined by the **learning rate**. \n",
    "   * A smaller learning rate means the network needs to see more minibatches before its weights converge to their best values. \n",
    "- The **learning rate** and the **size of the minibatches** are the two parameters that have the largest effect on how the SGD training proceeds. \n",
    "   * Their interaction is often subtle and the right choice for these parameters isn't always obvious. \n",
    "- **Adam** is an SGD algorithm that has an adaptive learning rate that makes it suitable for most problems without any parameter tuning (it is \"self tuning\", in a sense). Adam is a great general-purpose optimizer."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mae\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nb**: Notice that we are able to specify the loss and optimizer with just a string. You can also access these directly through the Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>CloseUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HSI</td>\n",
       "      <td>1986-12-31</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>333.879006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HSI</td>\n",
       "      <td>1987-01-02</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330.213013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HSI</td>\n",
       "      <td>1987-01-05</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>331.811987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HSI</td>\n",
       "      <td>1987-01-06</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.906987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HSI</td>\n",
       "      <td>1987-01-07</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>338.923013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Index        Date         Open         High          Low        Close  \\\n",
       "0   HSI  1986-12-31  2568.300049  2568.300049  2568.300049  2568.300049   \n",
       "1   HSI  1987-01-02  2540.100098  2540.100098  2540.100098  2540.100098   \n",
       "2   HSI  1987-01-05  2552.399902  2552.399902  2552.399902  2552.399902   \n",
       "3   HSI  1987-01-06  2583.899902  2583.899902  2583.899902  2583.899902   \n",
       "4   HSI  1987-01-07  2607.100098  2607.100098  2607.100098  2607.100098   \n",
       "\n",
       "     Adj Close  Volume    CloseUSD  \n",
       "0  2568.300049     0.0  333.879006  \n",
       "1  2540.100098     0.0  330.213013  \n",
       "2  2552.399902     0.0  331.811987  \n",
       "3  2583.899902     0.0  335.906987  \n",
       "4  2607.100098     0.0  338.923013  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "df = pd.read_csv('dataset/indexProcessed.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['000001.SS', '399001.SZ', 'GDAXI', 'GSPTSE', 'HSI', 'IXIC',\n",
       "       'J203.JO', 'N100', 'N225', 'NSEI', 'NYA', 'SSMI', 'TWII'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "a = le.fit(df['Index'])\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>CloseUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1986-12-31</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>333.879006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1987-01-02</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330.213013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1987-01-05</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>331.811987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1987-01-06</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.906987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1987-01-07</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>338.923013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104219</th>\n",
       "      <td>6</td>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>66054.921880</td>\n",
       "      <td>66812.453130</td>\n",
       "      <td>66022.976560</td>\n",
       "      <td>66076.679690</td>\n",
       "      <td>66076.679690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4625.367578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104220</th>\n",
       "      <td>6</td>\n",
       "      <td>2021-05-26</td>\n",
       "      <td>66076.679690</td>\n",
       "      <td>66446.367190</td>\n",
       "      <td>66030.351560</td>\n",
       "      <td>66108.226560</td>\n",
       "      <td>66108.226560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4627.575859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104221</th>\n",
       "      <td>6</td>\n",
       "      <td>2021-05-27</td>\n",
       "      <td>66108.226560</td>\n",
       "      <td>66940.250000</td>\n",
       "      <td>66102.546880</td>\n",
       "      <td>66940.250000</td>\n",
       "      <td>66940.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4685.817500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104222</th>\n",
       "      <td>6</td>\n",
       "      <td>2021-05-28</td>\n",
       "      <td>66940.250000</td>\n",
       "      <td>67726.562500</td>\n",
       "      <td>66794.609380</td>\n",
       "      <td>67554.859380</td>\n",
       "      <td>67554.859380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4728.840157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104223</th>\n",
       "      <td>6</td>\n",
       "      <td>2021-05-31</td>\n",
       "      <td>67554.859380</td>\n",
       "      <td>68140.851560</td>\n",
       "      <td>67554.859380</td>\n",
       "      <td>67964.039060</td>\n",
       "      <td>67964.039060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4757.482734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104224 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Index        Date          Open          High           Low  \\\n",
       "0           4  1986-12-31   2568.300049   2568.300049   2568.300049   \n",
       "1           4  1987-01-02   2540.100098   2540.100098   2540.100098   \n",
       "2           4  1987-01-05   2552.399902   2552.399902   2552.399902   \n",
       "3           4  1987-01-06   2583.899902   2583.899902   2583.899902   \n",
       "4           4  1987-01-07   2607.100098   2607.100098   2607.100098   \n",
       "...       ...         ...           ...           ...           ...   \n",
       "104219      6  2021-05-25  66054.921880  66812.453130  66022.976560   \n",
       "104220      6  2021-05-26  66076.679690  66446.367190  66030.351560   \n",
       "104221      6  2021-05-27  66108.226560  66940.250000  66102.546880   \n",
       "104222      6  2021-05-28  66940.250000  67726.562500  66794.609380   \n",
       "104223      6  2021-05-31  67554.859380  68140.851560  67554.859380   \n",
       "\n",
       "               Close     Adj Close  Volume     CloseUSD  \n",
       "0        2568.300049   2568.300049     0.0   333.879006  \n",
       "1        2540.100098   2540.100098     0.0   330.213013  \n",
       "2        2552.399902   2552.399902     0.0   331.811987  \n",
       "3        2583.899902   2583.899902     0.0   335.906987  \n",
       "4        2607.100098   2607.100098     0.0   338.923013  \n",
       "...              ...           ...     ...          ...  \n",
       "104219  66076.679690  66076.679690     0.0  4625.367578  \n",
       "104220  66108.226560  66108.226560     0.0  4627.575859  \n",
       "104221  66940.250000  66940.250000     0.0  4685.817500  \n",
       "104222  67554.859380  67554.859380     0.0  4728.840157  \n",
       "104223  67964.039060  67964.039060     0.0  4757.482734  \n",
       "\n",
       "[104224 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Index'] = le.transform(df['Index'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the type of data from string to datetime that allows easy handling of time-series analysis. \n",
    "df = df.astype({'Date':'datetime64[ns]'})\n",
    "df['Year'] = df['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Pull out the CloseUSD value based on the index and date\n",
    "'''\n",
    "def getPrice(x, df):\n",
    "    df = df.loc[(df['Index']  == x['Index'])  & (df['Date'] == x['Date'])]\n",
    "    if len(df['CloseUSD'])>0:\n",
    "        return df['CloseUSD'].values[0]\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>CloseUSD</th>\n",
       "      <th>Year</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1986-12-31</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>333.879006</td>\n",
       "      <td>1986</td>\n",
       "      <td>191.056328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1987-01-02</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330.213013</td>\n",
       "      <td>1987</td>\n",
       "      <td>183.471992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>1987-01-05</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>331.811987</td>\n",
       "      <td>1987</td>\n",
       "      <td>218.652793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1987-01-06</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.906987</td>\n",
       "      <td>1987</td>\n",
       "      <td>331.756328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1987-01-07</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>338.923013</td>\n",
       "      <td>1987</td>\n",
       "      <td>263.355352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index       Date         Open         High          Low        Close  \\\n",
       "0      4 1986-12-31  2568.300049  2568.300049  2568.300049  2568.300049   \n",
       "1      4 1987-01-02  2540.100098  2540.100098  2540.100098  2540.100098   \n",
       "2      4 1987-01-05  2552.399902  2552.399902  2552.399902  2552.399902   \n",
       "3      4 1987-01-06  2583.899902  2583.899902  2583.899902  2583.899902   \n",
       "4      4 1987-01-07  2607.100098  2607.100098  2607.100098  2607.100098   \n",
       "\n",
       "     Adj Close  Volume    CloseUSD  Year       Price  \n",
       "0  2568.300049     0.0  333.879006  1986  191.056328  \n",
       "1  2540.100098     0.0  330.213013  1987  183.471992  \n",
       "2  2552.399902     0.0  331.811987  1987  218.652793  \n",
       "3  2583.899902     0.0  335.906987  1987  331.756328  \n",
       "4  2607.100098     0.0  338.923013  1987  263.355352  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look for last day of an year for an Index\n",
    "df_last_date = df.groupby(['Index', 'Year']).agg({'Date':['max']})\n",
    "\n",
    "#reduce the column hierarachy to one.\n",
    "df_last_date.columns = df_last_date.columns.get_level_values(0)\n",
    "\n",
    "df_last_date.reset_index(inplace = True)\n",
    "\n",
    "\n",
    "#Look for the price in the main df dataframe for last date of a year for an Index\n",
    "df['Price'] = df_last_date.apply(lambda x: getPrice(x, df), axis = 1)\n",
    "df.head(5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>CloseUSD</th>\n",
       "      <th>Year</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>2568.300049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>333.879006</td>\n",
       "      <td>1986</td>\n",
       "      <td>191.056328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>2540.100098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330.213013</td>\n",
       "      <td>1987</td>\n",
       "      <td>183.471992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>2552.399902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>331.811987</td>\n",
       "      <td>1987</td>\n",
       "      <td>218.652793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>2583.899902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>335.906987</td>\n",
       "      <td>1987</td>\n",
       "      <td>331.756328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>2607.100098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>338.923013</td>\n",
       "      <td>1987</td>\n",
       "      <td>263.355352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index         Open         High          Low        Close    Adj Close  \\\n",
       "0      4  2568.300049  2568.300049  2568.300049  2568.300049  2568.300049   \n",
       "1      4  2540.100098  2540.100098  2540.100098  2540.100098  2540.100098   \n",
       "2      4  2552.399902  2552.399902  2552.399902  2552.399902  2552.399902   \n",
       "3      4  2583.899902  2583.899902  2583.899902  2583.899902  2583.899902   \n",
       "4      4  2607.100098  2607.100098  2607.100098  2607.100098  2607.100098   \n",
       "\n",
       "   Volume    CloseUSD  Year       Price  \n",
       "0     0.0  333.879006  1986  191.056328  \n",
       "1     0.0  330.213013  1987  183.471992  \n",
       "2     0.0  331.811987  1987  218.652793  \n",
       "3     0.0  335.906987  1987  331.756328  \n",
       "4     0.0  338.923013  1987  263.355352  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['Date'])\n",
    "df.dropna(subset = [\"Price\"], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>CloseUSD</th>\n",
       "      <th>Year</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>4</td>\n",
       "      <td>2661.500000</td>\n",
       "      <td>2661.500000</td>\n",
       "      <td>2661.500000</td>\n",
       "      <td>2661.500000</td>\n",
       "      <td>2661.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>345.995000</td>\n",
       "      <td>1988</td>\n",
       "      <td>7477.029785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>4</td>\n",
       "      <td>3133.699951</td>\n",
       "      <td>3133.699951</td>\n",
       "      <td>3133.699951</td>\n",
       "      <td>3133.699951</td>\n",
       "      <td>3133.699951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>407.380994</td>\n",
       "      <td>1987</td>\n",
       "      <td>11481.472676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>4</td>\n",
       "      <td>2432.000000</td>\n",
       "      <td>2432.000000</td>\n",
       "      <td>2432.000000</td>\n",
       "      <td>2432.000000</td>\n",
       "      <td>2432.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.160000</td>\n",
       "      <td>1988</td>\n",
       "      <td>372.290391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>4</td>\n",
       "      <td>2591.399902</td>\n",
       "      <td>2591.399902</td>\n",
       "      <td>2591.399902</td>\n",
       "      <td>2591.399902</td>\n",
       "      <td>2591.399902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>336.881987</td>\n",
       "      <td>1988</td>\n",
       "      <td>528.690002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Index         Open         High          Low        Close    Adj Close  \\\n",
       "366      4  2661.500000  2661.500000  2661.500000  2661.500000  2661.500000   \n",
       "113      4  3133.699951  3133.699951  3133.699951  3133.699951  3133.699951   \n",
       "426      4  2432.000000  2432.000000  2432.000000  2432.000000  2432.000000   \n",
       "320      4  2591.399902  2591.399902  2591.399902  2591.399902  2591.399902   \n",
       "\n",
       "     Volume    CloseUSD  Year         Price  \n",
       "366     0.0  345.995000  1988   7477.029785  \n",
       "113     0.0  407.380994  1987  11481.472676  \n",
       "426     0.0  316.160000  1988    372.290391  \n",
       "320     0.0  336.881987  1988    528.690002  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create training and validation splits\n",
    "df_train = df.sample(frac=0.7, random_state=0)\n",
    "df_valid = df.drop(df_train.index)\n",
    "display(df_train.head(4))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Scale to [0, 1]\n",
    "max_ = df_train.max(axis=0)\n",
    "min_ = df_train.min(axis=0)\n",
    "df_train = (df_train - min_) / (max_ - min_)\n",
    "df_valid = (df_valid - min_) / (max_ - min_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X_train = df_train.drop('Price', axis=1)\n",
    "X_valid = df_valid.drop('Price', axis=1)\n",
    "\n",
    "y_train = df_train['Price']\n",
    "y_valid = df_valid['Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(304, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>CloseUSD</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>4</td>\n",
       "      <td>2661.500000</td>\n",
       "      <td>2661.500000</td>\n",
       "      <td>2661.500000</td>\n",
       "      <td>2661.500000</td>\n",
       "      <td>2661.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>345.995000</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>4</td>\n",
       "      <td>3133.699951</td>\n",
       "      <td>3133.699951</td>\n",
       "      <td>3133.699951</td>\n",
       "      <td>3133.699951</td>\n",
       "      <td>3133.699951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>407.380994</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>4</td>\n",
       "      <td>2432.000000</td>\n",
       "      <td>2432.000000</td>\n",
       "      <td>2432.000000</td>\n",
       "      <td>2432.000000</td>\n",
       "      <td>2432.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>316.160000</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>4</td>\n",
       "      <td>2591.399902</td>\n",
       "      <td>2591.399902</td>\n",
       "      <td>2591.399902</td>\n",
       "      <td>2591.399902</td>\n",
       "      <td>2591.399902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>336.881987</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>2559.100098</td>\n",
       "      <td>2559.100098</td>\n",
       "      <td>2559.100098</td>\n",
       "      <td>2559.100098</td>\n",
       "      <td>2559.100098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>332.683013</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>4</td>\n",
       "      <td>2744.899902</td>\n",
       "      <td>2744.899902</td>\n",
       "      <td>2744.899902</td>\n",
       "      <td>2744.899902</td>\n",
       "      <td>2744.899902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>356.836987</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>4</td>\n",
       "      <td>3768.399902</td>\n",
       "      <td>3768.399902</td>\n",
       "      <td>3768.399902</td>\n",
       "      <td>3768.399902</td>\n",
       "      <td>3768.399902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>489.891987</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>4</td>\n",
       "      <td>2663.500000</td>\n",
       "      <td>2663.500000</td>\n",
       "      <td>2663.500000</td>\n",
       "      <td>2663.500000</td>\n",
       "      <td>2663.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>346.255000</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>4</td>\n",
       "      <td>2659.899902</td>\n",
       "      <td>2659.899902</td>\n",
       "      <td>2659.899902</td>\n",
       "      <td>2659.899902</td>\n",
       "      <td>2659.899902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>345.786987</td>\n",
       "      <td>1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>4</td>\n",
       "      <td>2509.699951</td>\n",
       "      <td>2509.699951</td>\n",
       "      <td>2488.199951</td>\n",
       "      <td>2488.199951</td>\n",
       "      <td>2488.199951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>323.465994</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Index         Open         High          Low        Close    Adj Close  \\\n",
       "366      4  2661.500000  2661.500000  2661.500000  2661.500000  2661.500000   \n",
       "113      4  3133.699951  3133.699951  3133.699951  3133.699951  3133.699951   \n",
       "426      4  2432.000000  2432.000000  2432.000000  2432.000000  2432.000000   \n",
       "320      4  2591.399902  2591.399902  2591.399902  2591.399902  2591.399902   \n",
       "10       4  2559.100098  2559.100098  2559.100098  2559.100098  2559.100098   \n",
       "..     ...          ...          ...          ...          ...          ...   \n",
       "377      4  2744.899902  2744.899902  2744.899902  2744.899902  2744.899902   \n",
       "182      4  3768.399902  3768.399902  3768.399902  3768.399902  3768.399902   \n",
       "388      4  2663.500000  2663.500000  2663.500000  2663.500000  2663.500000   \n",
       "80       4  2659.899902  2659.899902  2659.899902  2659.899902  2659.899902   \n",
       "258      4  2509.699951  2509.699951  2488.199951  2488.199951  2488.199951   \n",
       "\n",
       "     Volume    CloseUSD  Year  \n",
       "366     0.0  345.995000  1988  \n",
       "113     0.0  407.380994  1987  \n",
       "426     0.0  316.160000  1988  \n",
       "320     0.0  336.881987  1988  \n",
       "10      0.0  332.683013  1987  \n",
       "..      ...         ...   ...  \n",
       "377     0.0  356.836987  1988  \n",
       "182     0.0  489.891987  1987  \n",
       "388     0.0  346.255000  1988  \n",
       "80      0.0  345.786987  1987  \n",
       "258     0.0  323.465994  1988  \n",
       "\n",
       "[304 rows x 9 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(512, activation='relu', input_shape=[9]),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Deciding the architecture of your model should be part of a process. Start simple and use the validation loss as your guide. You'll learn more about model development in the exercises.\n",
    "\n",
    "After defining the model, we compile in the optimizer and loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mae',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now we're ready to start the training! We've told Keras to feed the optimizer 256 rows of the training data at a time *(the batch_size)* and to do that 10 times all the way through the dataset *(the epochs*).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train=np.asarray(X_train).astype(np.int)\n",
    "\n",
    "y_train=np.asarray(y_train).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000016CDE8220D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Constant constructor takes either 0 or 2 positional arguments\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000016CDE8220D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Constant constructor takes either 0 or 2 positional arguments\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000016CDE8220D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Constant constructor takes either 0 or 2 positional arguments\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 3124.0483WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000016CE06954C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Constant constructor takes either 0 or 2 positional arguments\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000016CE06954C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Constant constructor takes either 0 or 2 positional arguments\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000016CE06954C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: Constant constructor takes either 0 or 2 positional arguments\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2/2 [==============================] - 3s 2s/step - loss: 3032.4202 - val_loss: 2805.9705\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 2703.9098 - val_loss: 2773.6973\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 2706.7569 - val_loss: 2768.0664\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 2694.7135 - val_loss: 2796.7827\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 2723.2428 - val_loss: 2768.2024\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 2729.0768 - val_loss: 2756.2417\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 2649.4784 - val_loss: 2775.6545\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 2724.7284 - val_loss: 2754.0996\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 2701.0724 - val_loss: 2777.8994\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 2719.7420 - val_loss: 2802.0508\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 2665.3252 - val_loss: 2776.6863\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 2696.5563 - val_loss: 2754.9668\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 2714.0218 - val_loss: 2760.9839\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 2705.5184 - val_loss: 2766.9766\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 2678.5326 - val_loss: 2757.0928\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 2689.3969 - val_loss: 2753.0791\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 2670.6692 - val_loss: 2754.0293\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 2712.6398 - val_loss: 2760.6067\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 2659.0003 - val_loss: 2764.1155\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 2689.8503 - val_loss: 2759.5618\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=256,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We can see that Keras will keep you updated on the loss as the model trains.\n",
    "\n",
    "Often, a better way to view the loss though is to plot it. The **fit** method in fact keeps a record of the loss produced during training in a **History** object. We'll convert the data to a Pandas dataframe, which makes the plotting easy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert the training history to a dataframe\n",
    "history_df = pd.DataFrame(history.history)\n",
    "# use Pandas native plot method\n",
    "history_df['loss'].plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the loss levels off as the epochs go by. When the loss curve becomes horizontal like that, it means the model has learned all it can and there would be no reason continue for additional epochs."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Setup plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from learntools.deep_learning_intro.dltools import animate_sgd\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "# Setup feedback system\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.deep_learning_intro.ex3 import *\n",
    "\n",
    "\n",
    "learning_rate = 0.05\n",
    "batch_size = 32\n",
    "num_examples = 256\n",
    "\n",
    "animate_sgd(\n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=batch_size,\n",
    "    num_examples=num_examples,\n",
    "    # You can also change these, if you like\n",
    "    steps=50, # total training steps (batches seen)\n",
    "    true_w=3.0, # the slope of the data\n",
    "    true_b=2.0, # the bias of the data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4:  SGD on simple linear regression (Animated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's keep in mind that the Gradient Descent method is one of the most widely used parameter optimization algorithms in machine learning today.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis module allows us to create animated graphs during the gradient descent\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This module allows us to create animated graphs during the gradient descent\n",
    "'''\n",
    "#pip install celluloid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, a straight line in two-dimensional space can be described with the following function:  \n",
    "- y= w*x+b\n",
    "     * with w representing the slope (or “weight) \n",
    "     * and b representing the y-intercept (or “bias”) of our line. \n",
    "     \n",
    "There are numerous methods on how to determine the optimal values for w and b given our n data points. \n",
    "- The gradient descent algorithm aims to minimize the *mean squared error* between observed data points (y) and points we predicted with our regression line (ŷ). \n",
    "- The mean squared error is also being referred to as ‘cost function’ (or ‘costs’) usually denoted as J."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/cost_equation.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='img/cost_equation.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the cost function is only dependent on the parameters w and b.\n",
    "--> We aim to adjust our parameters until the cost function reaches its minimum.\n",
    "- here are the parameters we introduce the gradient of our cost function ∇J(w,b):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/cost_parameters.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='img/cost_parameters.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with δJ/δw and δJ/δb being the partial derivatives of J with respect to w and b respectively. \n",
    "* By constantly moving our parameters in the opposite direction of the current gradient ∇J, we can stepwise reduce the costs J. \n",
    "* The size of the steps we take to reach the (local/global) minimum of J is usually denoted as α and is also referred to as ‘learning rate’. \n",
    "* When training our model, our objective is to repeat the following for each epoch until we reach convergence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/conv_sys.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='img/conv_sys.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Gradient descent algorithm can be sub-classified according to how much of the training \n",
    "data is being used simultaneously to compute the gradient of our cost function. \n",
    "In the following example, we use the entire dataset for every update respectively, \n",
    "which is also referred to as batch gradient descent. \n",
    "In Python we import some useful libraries and set up our simple linear regression model:\n",
    "'''\n",
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import celluloid\n",
    "from celluloid import Camera\n",
    "import pandas_alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pillow', 'html']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.animation as manimation\n",
    "manimation.writers.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear regression model:\n",
    "class LinearRegression(object):\n",
    "    def __init__(self,w=1,b=1, lr=0.01): \n",
    "        self.lr=lr\n",
    "        self.w=np.array([[w]])\n",
    "        self.b=np.array([b])\n",
    "\n",
    "    def cost(self,x,y):     \n",
    "        pred = x@self.w+self.b  # predicted y-values\n",
    "        e=y-pred             # error term\n",
    "        return np.mean(e**2)  # mean squared error\n",
    "\n",
    "    def fit(self, x,y):\n",
    "        pred = x@self.w+self.b\n",
    "        e=y-pred\n",
    "        dJ_dw=(np.mean(e*(-2*x), axis=0)) # partial derivate of J with respect to w\n",
    "        dJ_db=(np.mean(e*(-2),axis=0)) # partial derivate of J with respect to b\n",
    "        self.w = (self.w.T-self.lr*dJ_dw).T  # update w\n",
    "        self.b = self.b - self.lr*dJ_db    # update b\n",
    "\n",
    "    def predict(self, x):\n",
    "        return (x @ self.w.T + self.b)  # return predicted values\n",
    "\n",
    "    def params(self):\n",
    "        return (self.w,self.b)   # return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then want to introduce our training data, define the learning rate (α=0.001), initialize our starting parameters (w=3, b=-1), and finally train our model. For every epoch, we store the updated values of our parameters, the costs, and some particular predicted y-values in lists. List items are then being stored in numpy arrays where they serve as raw data for our animated plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce training data\n",
    "x_train = np.array([     \n",
    "    [1],\n",
    "    [2],\n",
    "    [4],\n",
    "    [5],\n",
    "    [6],\n",
    "    [7]\n",
    "])\n",
    "\n",
    "y_train = np.array([     \n",
    "    [4],\n",
    "    [-12],\n",
    "    [3],\n",
    "    [-11],\n",
    "    [-5],\n",
    "    [-17]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce lists where data points are being stored: \n",
    "w_list=[]   # list contains weights\n",
    "b_list=[]   # list contains biases\n",
    "c_list=[]   # list contains costs \n",
    "ys_list=[]  # store arrays of predicted y-values for xs ( -> plot regression line!) \n",
    "cl_list = [] # list contains predicted y-values for x_train ( -> plot connecting lines!) \n",
    "\n",
    "xs= np.array([    # set x-values for regression line plot               \n",
    "            [-3],\n",
    "             [10]\n",
    "             ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model: \n",
    "model=LinearRegression(w=3,b=-1,lr=0.001) # set initial parameters and learning rate \n",
    "\n",
    "for i in range(60000):      # set number of epochs\n",
    "    w_list.append(model.params()[0])    # append weights (=slopes) to list\n",
    "    b_list.append(model.params()[1])    # append biases (=y-intercepts) to list\n",
    "    c_list.append(model.cost(x_train,y_train))  # append costs to list\n",
    "    ys_list.append(model.predict(xs).T)     # append pairs of predicted y-values for xs \n",
    "    cl_list.append(model.predict(x_train).T) # append predicted y-values for x_train to list\n",
    "    model.fit(x_train, y_train) # fit model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: [[-2.]]\n",
      "y-intercept: [2.]\n",
      "costs: 42.66666666666668\n"
     ]
    }
   ],
   "source": [
    "# print parameters and costs after all epochs\n",
    "print(\"weight: \" + str( model.params()[0]) )  \n",
    "print(\"y-intercept: \" + str( model.params()[1]) )\n",
    "print(\"costs: \"+ str(model.cost(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the particularly small learning rate of 0.001 was chosen on purpose to prevent overly large steps during the first epochs of gradient descent. A larger learning rate (e.g. α=0.1) usually results in faster model convergence requiring fewer epochs. However, overly large steps during the first epochs of gradient descent tend to result in less appealing animations or even failure to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.]]\n",
      "[2.]\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(x_train, y_train)\n",
    "print(reg.coef_)\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Animations of gradient descent (simple linear regression):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our data points being generated and stored, we can now start to build some animations. We could, for example, plot the values our cost function and parameters take on with respect to the epoch while plotting the corresponding regression line simultaneously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which epochs/data points to plot\n",
    "a=np.arange(0,50,1).tolist()\n",
    "b=np.arange(50,100,5).tolist()\n",
    "c=np.arange(100,12000,200).tolist()\n",
    "p = a+b+c # points we want to plot\n",
    "\n",
    "# Turn lists into arrays\n",
    "w= np.array(w_list).flatten()\n",
    "b= np.array(b_list).flatten()\n",
    "c= np.array(c_list).flatten()\n",
    "ys = np.array(ys_list) \n",
    "p=np.array(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
      "<ipython-input-42-d9266e54ee20>:6: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax1=fig.add_subplot(3, 2, 2)\n",
      "<ipython-input-42-d9266e54ee20>:11: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis.\n",
      "<ipython-input-42-d9266e54ee20>:16: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax3=fig.add_subplot(3, 2, 6, sharex=ax1)\n",
      "<ipython-input-42-d9266e54ee20>:22: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax0=fig.add_subplot(1, 2, 1) # plot fit\n"
     ]
    }
   ],
   "source": [
    "# Create first animation: \n",
    "fig = plt.figure(figsize=(10,10)) # create figure\n",
    "labelsize_ = 14\n",
    "camera = Camera(fig)  # create camera\n",
    "for i in p:\n",
    "    ax1=fig.add_subplot(3, 2, 2)  \n",
    "    ax1.plot(w[0:i], color='blue', linestyle=\"dashed\", alpha=0.5)\n",
    "    ax1.set_title(\"w\", fontsize=17)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=labelsize_)\n",
    "\n",
    "    ax2=fig.add_subplot(3, 2, 4, sharex=ax1) # right plots share x-axis. \n",
    "    ax2.plot(b[0:i], color='red', linestyle=\"dashed\", alpha=0.5)\n",
    "    ax2.set_title(\"b\", fontsize=17)\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=labelsize_)\n",
    "\n",
    "    ax3=fig.add_subplot(3, 2, 6, sharex=ax1) \n",
    "    ax3.plot(c[0:i],color='black',linestyle=\"dashed\")\n",
    "    ax3.set_title(\"costs\", fontsize=17)\n",
    "    ax3.tick_params(axis='both', which='major', labelsize=labelsize_)\n",
    "    ax3.set_xlabel(\"epochs\", fontsize=14, labelpad=10)\n",
    "\n",
    "    ax0=fig.add_subplot(1, 2, 1) # plot fit\n",
    "    leg=ax0.plot(xs.T.flatten(),ys[i].flatten(),\n",
    "                 color='r', label=str(i))  # set legend; flatten arrays to get plots!\n",
    "    ax0.scatter(x_train, y_train, color='b',marker='x', s=44)\n",
    "    ax0.legend(leg,[f'epochs: {i}'], loc='upper right', fontsize=15)\n",
    "    ax0.set_title(\"Linear fit\", fontsize=25)\n",
    "    ax0.tick_params(axis='both', which='major', labelsize=labelsize_)\n",
    "    ax0.set_xlabel(\"x\", fontsize=25, labelpad=10)\n",
    "    ax0.set_ylabel(\"y\", fontsize=25, labelpad=10)\n",
    "    ax0.tick_params(axis='both', which='major', labelsize=labelsize_) \n",
    "    ax0.set_ylim([-20, 10])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    #camera.snap() # take snapshot after each frame/iteration\n",
    "    \n",
    "animation = camera.animate(interval = 5,\n",
    "                          repeat = False, repeat_delay = 500) # create animation \n",
    "#animation.save('SimpleLinReg_1.gif', writer = 'imagemagick') # save animation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my opinion, it makes sense to return the final values of J, w and b being plotted, so that we can make sure we roughly visualized model convergence in our animation despite not using all the points we stored during the fitting process. Especially in 3D-animations, it can sometimes be difficult to confirm the former just by looking at the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final parameters and costs portrayed in animations \n",
    "print(\"Slope: \" + str(w[i])) \n",
    "print(\"y-intercept: \" + str(b[i])) \n",
    "print(\"final costs: \" + str(c[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second animation\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "camera = Camera(fig)\n",
    "\n",
    "for i in p: # use the same points to plot as before \n",
    "    ax0=fig.add_subplot(2, 1, 1) \n",
    "    leg=ax0.plot(xs.T.flatten(),ys[i].flatten(), color='r', label=str(i))\n",
    "    ax0.scatter(x_train, y_train, color='b',marker='x', s=44)\n",
    "    ax0.vlines(x_train.T, ymin=y_train.T, ymax=cl_list[i],\n",
    "               linestyle=\"dashed\",color='r',alpha=0.3)    # plot connecting lines\n",
    "    ax0.legend(leg,[f'epochs: {i}'], loc='upper right', fontsize=15)\n",
    "    ax0.set_title(\"Linear fit\", fontsize=25)\n",
    "    ax0.tick_params(axis='both', which='major', labelsize=labelsize_)\n",
    "    ax0.set_xlabel(\"x\", fontsize=25, labelpad=10)\n",
    "    ax0.set_ylabel(\"y\", fontsize=25, labelpad=10)\n",
    "    ax0.tick_params(axis='both', which='major', labelsize=labelsize_) \n",
    "    ax0.set_ylim([-20, 10])\n",
    "    \n",
    "    ax1=fig.add_subplot(2, 2, 3) \n",
    "    ax1.plot(w[i], c[i], marker='x', markersize=13, color=\"orangered\")\n",
    "    ax1.plot(np.array(w_list).flatten(),np.array(c_list).flatten() ,\n",
    "             linestyle='dashed', color=\"blue\")\n",
    "    ax1.set_xlabel(\"w\", fontsize=25)\n",
    "    ax1.set_ylabel(\"costs\", fontsize=25, labelpad=10)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=labelsize_)\n",
    "\n",
    "    ax2=fig.add_subplot(2, 2, 4, sharey=ax1) \n",
    "    ax2.plot(b[i], c[i], marker='x', markersize=13, color=\"orangered\")\n",
    "    ax2.plot(np.array(b_list).flatten(),np.array(c_list).flatten() ,\n",
    "             linestyle='dashed', color=\"red\")\n",
    "    ax2.set_xlabel(\"b\", fontsize=25)\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=labelsize_)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    #camera.snap()\n",
    "    \n",
    "animation = camera.animate(interval = 5,\n",
    "                          repeat = False, repeat_delay = 500)\n",
    "#animation.save('SimpleLinReg_2.gif', writer = 'imagemagick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_3d(x,y,w,b):  # predicts costs for every pair of w and b. \n",
    "        pred = x@w.T+b                       \n",
    "        e=y-pred\n",
    "        return np.mean(e**2)\n",
    "        \n",
    "ws = np.linspace(-5, 5.0, 10) # set range of values for w and b for surface plot\n",
    "bs = np.linspace(-5, 5, 10)\n",
    "M, B = np.meshgrid(ws, bs) # create meshgrid\n",
    "\n",
    "zs = np.array([cost_3d(x_train,y_train,       # determine costs for each pair of w and b \n",
    "        np.array([[wp]]), np.array([[bp]]))  # cost_3d() only accepts wp and bp as matrices. \n",
    "               for wp, bp in zip(np.ravel(M), np.ravel(B))])\n",
    "Z = zs.reshape(M.shape) # get z-values for surface plot in shape of M."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third Animation\n",
    "fig = plt.figure(figsize=(10,10))  \n",
    "ax1=fig.add_subplot(121)\n",
    "ax1.set_title(\"Linear fit\", fontsize=30 )\n",
    "ax2 = fig.add_subplot(122, projection='3d') # projection='3d'\n",
    "ax2.set_title(\"cost function\", fontsize=30)\n",
    "ax2.view_init(elev=20., azim=145)           # set view\n",
    "camera = Camera(fig)\n",
    "\n",
    "for i in p:       \n",
    "    leg=ax1.plot(xs.T.flatten(),ys[i].flatten(), color='r', label=str(i))  \n",
    "    ax1.vlines(x_train.T, ymin=y_train.T, ymax=cl_list[i], linestyle=\"dashed\",\n",
    "               color='r',alpha=0.3)\n",
    "    ax1.scatter(x_train, y_train, color='b',marker='x', s=44)\n",
    "    ax1.legend(leg,[f'epochs: {i}'], loc='upper right', fontsize=15) \n",
    "    ax1.set_xlabel(\"x\", fontsize=25, labelpad=10)\n",
    "    ax1.set_ylabel(\"y\", fontsize=25, labelpad=10)\n",
    "    ax1.tick_params(axis='both', which='major', labelsize=15) \n",
    "    ax1.set_ylim([-20, 10])\n",
    "    \n",
    "    ax2.plot_surface(M, B, Z, rstride=1, cstride=1, color='b',\n",
    "                     alpha=0.35) # create surface plot\n",
    "    ax2.scatter(w[i],b[i],c[i],marker='o', s=12**2, color='orange' )\n",
    "    ax2.set_xlabel(\"w\", fontsize=25, labelpad=10)\n",
    "    ax2.set_ylabel(\"b\", fontsize=25, labelpad=10)\n",
    "    ax2.set_zlabel(\"costs\", fontsize=25,\n",
    "    labelpad=-35) # negative value for labelpad places z-label left of z-axis.\n",
    "    ax2.tick_params(axis='both', which='major', labelsize=15) \n",
    "    ax2.plot(w[0:i],b[0:i],c[0:i], linestyle=\"dashed\",linewidth=2,\n",
    "             color=\"grey\") # (dashed) lineplot\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    #camera.snap()\n",
    "    \n",
    "animation = camera.animate(interval = 5,\n",
    "                          repeat = False, repeat_delay = 500)\n",
    "#animation.save('SimpleLinReg_3.gif', writer = 'imagemagick')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae9390dff2a67ecfe7f518497ad1cfb27838edb064eb7518a1f306763d1e93e3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
