{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Project Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Action items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Sample code\n",
    "'''\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(feature_array, target_array, to_predict, learn_rate_type=\"invscaling\"):\n",
    "    \"\"\" Computes Ordinary Least SquaresLinear Regression with Stochastic Gradient Descent as the optimization algorithm.\n",
    "        :param feature_array: array with all feature vectors used to train the model\n",
    "        :param target_array: array with all target vectors used to train the model\n",
    "        :param to_predict: feature vector that is not contained in the training set. Used to make a new prediction\n",
    "        :param learn_rate_type: algorithm used to set the learning rate at each iteration.\n",
    "        :return: Predicted cooking time for the vector to_predict and the R-squared of the model.\n",
    "\"\"\"    # Pipeline of transformations to apply to an estimator. First applies Standard Scaling to the feature array.\n",
    "    # Then, when the model is fitting the data it runs Stochastic Gradient Descent as the optimization algorithm.\n",
    "    # The estimator is always the last element.\n",
    "    \n",
    "    start_time = time.time()\n",
    "    linear_regression_pipeline = make_pipeline(StandardScaler(), SGDRegressor(learning_rate=learn_rate_type))\n",
    "    \n",
    "    linear_regression_pipeline.fit(feature_array, target_array)\n",
    "    stop_time = time.time()\n",
    "     \n",
    "    print(\"Total runtime: %.6fs\" % (stop_time - start_time))\n",
    "    print(\"Algorithm used to set the learning rate: \" + learn_rate_type)\n",
    "    print(\"Model Coeffiecients: \" + str(linear_regression_pipeline[1].coef_))\n",
    "    print(\"Number of iterations: \" + str(linear_regression_pipeline[1].n_iter_))    # Make a prediction for a feature vector not in the training set\n",
    "    prediction = np.round(linear_regression_pipeline.predict(to_predict), 0)[0]\n",
    "    print(\"Predicted cooking time: \" + str(prediction) + \" minutes\")    \n",
    "    r_squared = np.round(linear_regression_pipeline.score(feature_array, target_array).reshape(-1, 1)[0][0], 2)\n",
    "    print(\"R-squared: \" + str(r_squared))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_array = [[500, 80, 30, 10],\n",
    "                 [550, 75, 25, 0],\n",
    "                 [475, 90, 35, 20],\n",
    "                 [450, 80, 20,25],\n",
    "                 [465, 75, 30, 0],\n",
    "                 [525, 65, 40, 15],\n",
    "                 [400, 85, 33, 0],\n",
    "                 [500, 60, 30, 30],\n",
    "                 [435, 45, 25, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_array = [17, 11, 21, 23, 22, 15, 25, 18, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_predict = [[510, 50, 35, 10]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 0.001998s\n",
      "Algorithm used to set the learning rate: invscaling\n",
      "Model Coeffiecients: [-3.44034236  1.64723444  0.28599174  1.10821407]\n",
      "Number of iterations: 249\n",
      "Predicted cooking time: 13.0 minutes\n",
      "R-squared: 0.9\n"
     ]
    }
   ],
   "source": [
    "stochastic_gradient_descent(feature_array, target_array, to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 0.002000s\n",
      "Algorithm used to set the learning rate: invscaling\n",
      "Model Coeffiecients: [-3.44226981  1.64672679  0.2866046   1.10902962]\n",
      "Number of iterations: 248\n",
      "Predicted cooking time: 13.0 minutes\n",
      "R-squared: 0.9\n"
     ]
    }
   ],
   "source": [
    "stochastic_gradient_descent(feature_array, target_array, to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runtime: 0.001999s\n",
      "Algorithm used to set the learning rate: adaptive\n",
      "Model Coeffiecients: [-3.49884884  1.64454487  0.3091154   1.15922034]\n",
      "Number of iterations: 97\n",
      "Predicted cooking time: 13.0 minutes\n",
      "R-squared: 0.91\n"
     ]
    }
   ],
   "source": [
    "stochastic_gradient_descent(feature_array, target_array, to_predict, learn_rate_type=\"adaptive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "With the limitations of Gradient Descent in mind, Stochastic Gradient Descent emerged as a way to tackle performance issues and speed up the convergence in large datasets.\n",
    "\n",
    "Stochastic Gradient Descent is a probabilistic approximation of Gradient Descent. It is an approximation because, at each step, the algorithm calculates the gradient for one observation picked at random, instead of calculating the gradient for the entire dataset.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae9390dff2a67ecfe7f518497ad1cfb27838edb064eb7518a1f306763d1e93e3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
